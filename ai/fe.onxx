import tensorflow as tf
import numpy as np
import onnxruntime as ort
import tf2onnx
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from PIL import Image
import os
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# Load Pre-trained MobileNetV2 Model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D()  # Flatten the features
])

# Convert the Model to ONNX Format and Save It
onnx_model_path = "feature_extractor.onnx"
spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name="input"),)
onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=11)

# Save ONNX model
with open(onnx_model_path, "wb") as f:
    f.write(onnx_model.SerializeToString())

print(f"Model saved as {onnx_model_path}")

# Load ONNX Model for Inference
session = ort.InferenceSession(onnx_model_path)

def preprocess_input_image(img_path):
    """Prepares an image for ONNX MobileNetV2 inference."""
    img = Image.open(img_path).convert('RGB')  # Ensure RGB mode
    img = img.resize((224, 224))  # Resize to MobileNetV2 input size
    img = np.array(img).astype(np.float32)  # Convert to float32
    img = np.expand_dims(img, axis=0) / 255.0  # Normalize and add batch dimension
    return img

def extract_features(img_path):
    """Extracts features from an image using the ONNX model."""
    img = preprocess_input_image(img_path)
    input_name = session.get_inputs()[0].name  # Get the correct input name
    features = session.run(None, {input_name: img})[0]
    return features.flatten()  # Flatten to a 1D vector

def extract_features_from_dataset(dataset_dir):
    """Extracts features from all images in the dataset."""
    features_list = []
    image_paths = []
    
    for root, dirs, files in os.walk(dataset_dir):
        for img_name in files:
            if img_name.lower().endswith(('jpg', 'jpeg', 'png', 'bmp')):
                img_path = os.path.join(root, img_name)
                try:
                    features = extract_features(img_path)
                    features_list.append(features)
                    image_paths.append(img_path)
                except Exception as e:
                    print(f"Error processing image {img_path}: {e}")
    
    return np.array(features_list), image_paths

def get_most_similar_images(user_img_path, dataset_dir, top_n=5):
    """Finds the most similar images to the given user image."""
    user_features = extract_features(user_img_path)
    dataset_features, image_paths = extract_features_from_dataset(dataset_dir)
    similarities = cosine_similarity([user_features], dataset_features)[0]
    most_similar_idx = np.argsort(similarities)[-top_n:][::-1]
    similar_images = [image_paths[idx] for idx in most_similar_idx]
    return similar_images, similarities[most_similar_idx]

def display_similar_images(user_img_path, similar_images, similarities):
    """Displays the most similar images alongside the user image."""
    img = Image.open(user_img_path)
    plt.figure(figsize=(12, 12))
    plt.subplot(3, 3, 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title("User Image")

    for i, (sim_img, similarity) in enumerate(zip(similar_images, similarities)):
        img = Image.open(sim_img)
        plt.subplot(3, 3, i+2)
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"Similarity: {similarity:.2f}")

    plt.show()

# Example Usage
user_img_path = '/kaggle/input/testing-imageskeshawa/womanSkirt.png'
dataset_dir = '/kaggle/input/moddelite/ModdeDataset/skirt'

# Find similar images
similar_images, similarities = get_most_similar_images(user_img_path, dataset_dir, top_n=5)

# Display the results
display_similar_images(user_img_path, similar_images, similarities)
